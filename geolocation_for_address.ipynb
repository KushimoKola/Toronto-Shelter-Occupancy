{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------WITHOUT GOOGLE MAP API-------------------\n",
    "\n",
    "import pandas as pd\n",
    "import geocoder\n",
    "\n",
    "# Path to your CSV file containing addresses\n",
    "input_csv_path = 'toronto_shelter_addresses.csv'\n",
    "output_csv_path = 'toronto_shelter_addresses_with_coordinates.csv'\n",
    "\n",
    "df = pd.read_csv(input_csv_path)\n",
    "\n",
    "# Create empty lists to store the longitude and latitude\n",
    "longitudes = []\n",
    "latitudes = []\n",
    "\n",
    "# Iterate over each shelter_address and apply geocoding\n",
    "for shelter_address in df['shelter_address']:\n",
    "    g = geocoder.geolytica(shelter_address)  # Use geolytica for geocoding\n",
    "    if g.latlng:  # If latlng is found\n",
    "        latitudes.append(g.latlng[0])  # Latitude\n",
    "        longitudes.append(g.latlng[1])  # Longitude\n",
    "    else:\n",
    "        latitudes.append(None)  # If not found, append None\n",
    "        longitudes.append(None)\n",
    "\n",
    "# Add the longitude and latitude to the DataFrame\n",
    "df['latitude'] = latitudes\n",
    "df['longitude'] = longitudes\n",
    "\n",
    "# Save the DataFrame to a new CSV file\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Geocoding completed. Results saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-79.3429848 43.6600165\n"
     ]
    }
   ],
   "source": [
    "# ----TEST IF THIS WORKS------\n",
    "\n",
    "\n",
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Define the Google API key (make sure your .env file has google_map_api_key)\n",
    "google_api_key = os.getenv('google_map_api_key')\n",
    "\n",
    "# Google Maps Geocoding API URL\n",
    "geocode_url = \"https://maps.googleapis.com/maps/api/geocode/json\"\n",
    "\n",
    "# Define the function to get latitude and longitude from Google Maps API\n",
    "def get_lat_lng(address, api_key):\n",
    "    params = {\n",
    "        'address': address,  # Use 'address' for Google API\n",
    "        'key': api_key\n",
    "    }\n",
    "    response = requests.get(geocode_url, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if len(data['results']) > 0:\n",
    "            location = data['results'][0]['geometry']['location']\n",
    "            return location['lat'], location['lng']\n",
    "        else:\n",
    "            print(f\"No results found for address: {address}\")\n",
    "    else:\n",
    "        print(f\"Error fetching data for address: {address}, Status code: {response.status_code}\")\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "# Test the function with a single address\n",
    "lat, lng = get_lat_lng('189B Booth Ave M4M 2M5 Toronto', google_api_key)\n",
    "print(lng, lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geocoding completed. Updated data saved to toronto_shelter_addresses_with_coordinate.csv\n"
     ]
    }
   ],
   "source": [
    "#----------------WITH GOOGLE MAP API--------------------\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "google_api_key = os.getenv('google_map_api_key')\n",
    "\n",
    "# Google Maps Geocoding API URL\n",
    "geocode_url = \"https://maps.googleapis.com/maps/api/geocode/json\"\n",
    "\n",
    "input_csv_path = 'toronto_shelter_addresses.csv' #Be sure to have  this in your wkdir\n",
    "output_csv_path = 'toronto_shelter_addresses_with_coordinate.csv'\n",
    "\n",
    "df = pd.read_csv(input_csv_path)\n",
    "\n",
    "# Ensure there are 'longitude' and 'latitude' columns; create them if they don't exist\n",
    "if 'longitude' not in df.columns:\n",
    "    df['longitude'] = None\n",
    "if 'latitude' not in df.columns:\n",
    "    df['latitude'] = None\n",
    "\n",
    "# Function to get latitude and longitude from Google Maps API\n",
    "def get_lat_lng(address, api_key):\n",
    "    params = {\n",
    "        'address': address, \n",
    "        'key': api_key\n",
    "    }\n",
    "    response = requests.get(geocode_url, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if len(data['results']) > 0:\n",
    "            location = data['results'][0]['geometry']['location']\n",
    "            return location['lat'], location['lng']\n",
    "        else:\n",
    "            print(f\"No results found for address: {address}\")\n",
    "    else:\n",
    "        print(f\"Error fetching data for address: {address}, Status code: {response.status_code}\")\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "# Iterate over each row in the DataFrame where longitude and latitude are missing\n",
    "for i, row in df.iterrows():\n",
    "    if pd.isna(row['longitude']) or pd.isna(row['latitude']):\n",
    "        shelter_address = row['shelter_address']  # Replace with the actual shelter_address column name in your CSV\n",
    "        \n",
    "        # Get latitude and longitude from Google API\n",
    "        latitude, longitude = get_lat_lng(shelter_address, google_api_key)\n",
    "        \n",
    "        # Update the DataFrame with the fetched latitude and longitude\n",
    "        if latitude and longitude:\n",
    "            df.at[i, 'latitude'] = latitude\n",
    "            df.at[i, 'longitude'] = longitude\n",
    "        else:\n",
    "            print(f\"Failed to geocode: {shelter_address}\")\n",
    "        \n",
    "        # Sleep for 1 second to avoid exceeding API rate limits\n",
    "        time.sleep(1)\n",
    "\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Geocoding completed. Updated data saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The table 'toronto_shelther_address' has been created or already exists.\n",
      "No new data to append.\n",
      "Temporary file 'temp.csv' has been deleted.\n",
      "An error occurred: Not an executable object: 'SELECT COUNT(*) FROM toronto.toronto_shelther_address'\n"
     ]
    }
   ],
   "source": [
    "# -------LOAD TO DATABASE ---------\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, MetaData, Table, Column, VARCHAR\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "from urllib.parse import quote_plus\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Path to your CSV file\n",
    "file_path = 'toronto_shelter_addresses_with_coordinate.csv'\n",
    "\n",
    "# Read the CSV data into a pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Simplify and consolidate column name formatting\n",
    "df.columns = df.columns.str.replace(' ', '_', regex=True).str.replace('[().?]', '', regex=True).str.lower()\n",
    "\n",
    "# Database connection details\n",
    "database_username = os.getenv('database_username')\n",
    "database_password = os.getenv('database_password')\n",
    "database_name = 'analytics_db'\n",
    "database_host = 'localhost'\n",
    "database_port = '5432'\n",
    "database_schema = 'toronto'\n",
    "\n",
    "database_connection_string = f'postgresql://{database_username}:{quote_plus(database_password)}@{database_host}:{database_port}/{database_name}'\n",
    "# Create a SQLAlchemy engine\n",
    "engine = create_engine(database_connection_string)\n",
    "\n",
    "# Initialize MetaData object\n",
    "metadata = MetaData()\n",
    "\n",
    "# Define columns for the table without conditions\n",
    "columns = [Column(column_name, VARCHAR) for column_name in df.columns]\n",
    "\n",
    "# Name of the table in PostgreSQL\n",
    "table_name = 'toronto_shelther_address'\n",
    "\n",
    "# Create a table with the defined columns within the specified schema\n",
    "table = Table(table_name, metadata, *columns, schema=database_schema, extend_existing=True)\n",
    "\n",
    "try:\n",
    "    # Create table if it doesn't exist\n",
    "    metadata.create_all(engine)\n",
    "    print(f\"The table '{table_name}' has been created or already exists.\")\n",
    "\n",
    "    # Insert data into the table or append if shelter_address does not exist\n",
    "    with engine.connect() as connection:\n",
    "        existing_addresses_query = f\"SELECT shelter_address FROM {database_schema}.{table_name}\"\n",
    "        existing_addresses = pd.read_sql(existing_addresses_query, connection)['shelter_address'].tolist()\n",
    "        \n",
    "        new_data = df[~df['shelter_address'].isin(existing_addresses)]\n",
    "        \n",
    "        if not new_data.empty:\n",
    "            new_data.to_sql(table_name, engine, if_exists='append', index=False, schema=database_schema)\n",
    "            print(f\"New data appended to '{table_name}'.\")\n",
    "        else:\n",
    "            print(f\"No new data to append.\")\n",
    "        # Remove the temporary file after the data is inserted\n",
    "        if os.path.exists(temp_csv_path):\n",
    "            os.remove(temp_csv_path)  # Delete the temporary CSV file\n",
    "            print(f\"Temporary file '{temp_csv_path}' has been deleted.\")\n",
    "\n",
    "    # Get and print the row counts after loading data\n",
    "    with engine.connect() as connection:\n",
    "        current_count = connection.execute(f\"SELECT COUNT(*) FROM {database_schema}.{table_name}\").scalar()\n",
    "        print(f\"The table '{table_name}' now has {current_count} rows after the update.\")\n",
    "except SQLAlchemyError as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".tsheltervenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
